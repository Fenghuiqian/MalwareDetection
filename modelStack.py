#!/usr/bin/env python
# coding: utf-8


import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, f1_score


# Read subModel features
def stacked_feature():
    CNN_TrainFeature = pd.read_csv("../data/results/textcnn_train_7k_5f_cw.csv", header=0, index_col=0,names=["CNN_P%s" % i for i in range(8)])
    CNN_TestFeature = pd.read_csv("../data/results/textcnn_test_7k_5average_cw.csv", header=0, index_col=0,names=["CNN_P%s" % i for i in range(8)])

    RNN_TrainFeature = pd.read_csv("../data/results/rcnn_train_5f.csv", header=0, index_col=0, names=["RNN_P%s" % i for i in range(8)])
    RNN_TestFeature = pd.read_csv("../data/results/rcnn_test_5average.csv", header=0, index_col=0, names=["RNN_P%s" % i for i in range(8)])

    LGBM_TrainFeature = pd.read_csv("../data/results/LGBM_StatisticFeature_train_5f.csv", header=0,index_col=0, names=["LGBM_P%s" % i for i in range(8)])
    LGBM_TestFeature = pd.read_csv("../data/results/LGBM_StatisticFeature_test_5average.csv", header=0, index_col=0, names=["LGBM_P%s" % i for i in range(8)])

    train_feature = pd.concat([LGBM_TrainFeature, CNN_TrainFeature, RNN_TrainFeature], axis=1)
    test_feature = pd.concat([LGBM_TestFeature, CNN_TestFeature, RNN_TestFeature], axis=1)

    return train_feature, test_feature



# LGBM Classifier
model = lgb.LGBMClassifier(objective="multiclass",
                           learning_rate=0.02,
                           n_estimators=1000,
                           num_leaves=31,
                           reg_alpha=1,
                           reg_lambda=1,
                           min_child_samples=10,
                           colsample_bytree=0.8,
                           subsample=0.8,
                           subsample_freq=3,
                           random_state=42
                           , class_weight='balanced')


if __name__ == '__main__':
    train_feature, test_feature = stacked_feature()

    # Label&FileId
    train =pd.read_csv("../data/security_train.zip", compression="zip",usecols=["file_id","label"], dtype = {'label':np.uint8,'file_id':np.uint32})
    test = pd.read_csv("../data/security_test.zip", compression="zip",usecols=["file_id"], index_col = None,dtype = {"file_id":np.uint32})
    train_Label = train.groupby(["file_id"])["label"].agg("first").reset_index().drop(["file_id"],axis=1)
    test_FileId = test.drop_duplicates().reset_index().file_id.values

    # 5skf fit
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    result_val = np.zeros(shape=(len(train_feature), 8))
    result_test = np.zeros(shape=(len(test_feature), 8))
    for i, (tr_index, val_index) in enumerate(skf.split(train_feature, train_Label)):
        tr_X, val_X = train_feature.iloc[tr_index, :], train_feature.iloc[val_index, :]
        tr_y, val_y = train_Label.iloc[tr_index, :], train_Label.iloc[val_index, :]

        model.fit(X=tr_X, y=tr_y, eval_set=[(val_X, val_y)], eval_metric="multi_logloss", early_stopping_rounds=5, verbose=10)

        pred_val_y = model.predict(val_X)
        accuracy = accuracy_score(y_pred=pred_val_y, y_true=val_y)
        f1 = f1_score(y_pred=pred_val_y, y_true=val_y, average="macro")
        print("正确率:", accuracy, "f1_score", f1)
        pred_val = model.predict_proba(val_X)
        result_val[[val_index]] = pred_val
        pred_test = model.predict_proba(test_feature)
        result_test += pred_test
    result_test /= 5


    # modify submit file
    submit = pd.DataFrame(result_test, columns=["prob%s" % i for i in range(8)], index=test_FileId)
    submit = submit.round(5)
    submit["prob7"] = 1-(submit["prob0"]+submit["prob1"]+submit["prob2"]+submit["prob3"]+submit["prob4"]+submit["prob5"]+submit["prob6"])
    submit = submit.round(5)
    submit.to_csv("../data/submits/submit.csv")
    lgb.plot_importance(model, figsize=(10, 10))



