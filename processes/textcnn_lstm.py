#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import numpy as np
import pandas as pd
import h5py
from keras.models import Model
from keras.layers import Input, Activation, Dense, Flatten, Dropout, Embedding
from keras.layers import Conv1D, MaxPooling1D, CuDNNLSTM
from keras.layers.merge import concatenate
from keras.layers.normalization import BatchNormalization
from keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.model_selection import StratifiedKFold


def textcnn_lstm(maxlen=7000):
    main_input = Input(shape=(maxlen,), dtype='float64')
    embedder = Embedding(304, 256, input_length=maxlen)
    embed = embedder(main_input)
    # cnn1模块，kernel_size = 3
    conv1_1 = Conv1D(16, 3, padding='same')(embed)
    bn1_1 = BatchNormalization()(conv1_1)
    relu1_1 = Activation('relu')(bn1_1)
    conv1_2 = Conv1D(32, 3, padding='same')(relu1_1)
    bn1_2 = BatchNormalization()(conv1_2)
    relu1_2 = Activation('relu')(bn1_2)
    cnn1 = MaxPooling1D(pool_size=4)(relu1_2)
    # cnn2模块，kernel_size = 4
    conv2_1 = Conv1D(16, 4, padding='same')(embed)
    bn2_1 = BatchNormalization()(conv2_1)
    relu2_1 = Activation('relu')(bn2_1)
    conv2_2 = Conv1D(32, 4, padding='same')(relu2_1)
    bn2_2 = BatchNormalization()(conv2_2)
    relu2_2 = Activation('relu')(bn2_2)
    cnn2 = MaxPooling1D(pool_size=4)(relu2_2)
    # cnn3模块，kernel_size = 5
    conv3_1 = Conv1D(16, 5, padding='same')(embed)
    bn3_1 = BatchNormalization()(conv3_1)
    relu3_1 = Activation('relu')(bn3_1)
    conv3_2 = Conv1D(32, 5, padding='same')(relu3_1)
    bn3_2 = BatchNormalization()(conv3_2)
    relu3_2 = Activation('relu')(bn3_2)
    cnn3 = MaxPooling1D(pool_size=4)(relu3_2)
    # 拼接三个模块
    cnn = concatenate([cnn1, cnn2, cnn3], axis=-1)
    lstm = CuDNNLSTM(256)(cnn)
    f = Flatten()(cnn1)
    fc = Dense(256, activation='relu')(f)
    D = Dropout(0.5)(fc)
    main_output = Dense(8, activation='softmax')(lstm)
    model = Model(inputs=main_input, outputs=main_output)

    return model


if __name__ == "__name__":
    # load seq data
    file = h5py.File("./data/malware_seq_3000.h5", "r+")
    print(list(file.keys()))
    pad_seq_train = np.array(file["seq_train_3000"])
    pad_seq_test = np.array(file["seq_test_3000"])
    train_label = np.array(file["label"])

    cls_wt = pd.Series(train_label).value_counts()
    cls_wt = cls_wt.sum()/cls_wt

    # skf5 model fit
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    result_val = np.zeros(shape=(len(pad_seq_train), 8))
    result_test = np.zeros(shape=(len(pad_seq_test), 8))
    for i, (tr_index, val_index) in enumerate(skf.split(pad_seq_train, train_label)):
        tr_X, val_X = pad_seq_train[[tr_index]], pad_seq_train[[val_index]]
        tr_y, val_y = train_label[[tr_index]], train_label[[val_index]]
        tr_y = pd.get_dummies(tr_y).values
        val_y = pd.get_dummies(val_y).values
        model = textcnn_lstm()
        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
        model_weight_name = "./data/weights/Model_textcnn_lstm_3k_weight_%s.pkl" % i
        early_stopping = EarlyStopping(monitor='val_loss', patience=10)
        checkpoint = ModelCheckpoint(model_weight_name, save_best_only=True, save_weights_only=True)
        # tensorBoard = keras.callbacks.TensorBoard(log_dir="./data/TXTCNN/Graph", histogram_freq=1, write_graph=True, write_images=True)

        model.fit(tr_X, tr_y,
                  validation_data=(val_X, val_y),
                  epochs=100, batch_size=16,
                  shuffle=True,
                  class_weight=cls_wt,
                  callbacks=[early_stopping, checkpoint])
        model.load_weights(model_weight_name)
        pred_val_X = model.predict(val_X, batch_size=64, verbose=1)
        pred_test = model.predict(pad_seq_test, batch_size=64, verbose=1)
        result_val[[val_index]] = pred_val_X
        result_test += pred_test
    result_test /= 5

    # save result
    pd.DataFrame(result_val).to_csv("data/results/textcnn_lstm_result_train_5f.csv")
    pd.DataFrame(result_test).to_csv("data/results/textcnn_lstm_result_test_5average.csv")
