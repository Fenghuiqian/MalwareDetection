#!/usr/bin/env python
# coding: utf-8


import numpy as np 
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder
import h5py
from keras.preprocessing.sequence import pad_sequences
from keras.layers import Dense, Input, Embedding, Dropout, Activation
from keras.layers import Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D, MaxPooling1D, Flatten
from keras.layers import SpatialDropout1D
from keras.layers.merge import concatenate
from keras.models import Model
from keras.optimizers import Adam
from keras.layers.normalization import BatchNormalization
from keras.callbacks import EarlyStopping, ModelCheckpoint



file = h5py.File("malware_seq_data_7000.h5", "r+")
pad_seq_train = np.array(file["pad_seq_train"]) 
pad_seq_test = np.array(file["pad_seq_test"]) 
train_label = np.array(file["train_label"])


# class weight
cls_wt = pd.Series(train_label).value_counts()
cls_wt = cls_wt.sum()/cls_wt


def CNN(emb_input_dim=301,
        emb_output_dim=128,
        pad_length=7000,
        num_filters=64):
    inp = Input(shape=(pad_length,),dtype="int32")
    embed = Embedding(emb_input_dim, emb_output_dim, input_length=pad_length, mask_zero=False)(inp)
    space_Dropout = embed = SpatialDropout1D(0.2)(embed)
    conv_2 = Conv1D(filters=num_filters, kernel_size=2, activation="relu")(space_Dropout)
    max_Pool_2 = GlobalMaxPooling1D()(conv_2)
    conv_4 = Conv1D(filters=num_filters, kernel_size=4, activation="relu")(space_Dropout)
    max_Pool_4 = GlobalMaxPooling1D()(conv_4)
    conv_6 = Conv1D(filters=num_filters, kernel_size=6, activation="relu")(space_Dropout)
    max_Pool_6 = GlobalMaxPooling1D()(conv_6)
    conv_8 = Conv1D(filters=num_filters, kernel_size=8, activation="relu")(space_Dropout)
    max_Pool_8 = GlobalMaxPooling1D()(conv_8)
    conv_10 = Conv1D(filters=num_filters, kernel_size=10, activation="relu")(space_Dropout)
    max_Pool_10 = GlobalMaxPooling1D()(conv_10)
    # concat
    fc = concatenate([max_Pool_2,max_Pool_4,max_Pool_6,max_Pool_8,max_Pool_10])
    fc = Dropout(0.4)(fc)
    fc = Dense(256, activation='relu')(fc)
    outp = Dense(8, activation = 'softmax')(fc)
    
    model = Model(inputs= inp, outputs=outp)
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    
    return model
    


skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
result_val = np.zeros(shape=(len(pad_seq_train), 8))
result_test = np.zeros(shape=(len(pad_seq_test), 8))
for i, (tr_index, val_index) in enumerate(skf.split(pad_seq_train, train_label)):

    tr_X, val_X = pad_seq_train[[tr_index]], pad_seq_train[[val_index]]
    tr_y, val_y = train_label[[tr_index]], train_label[[val_index]]
    tr_y = pd.get_dummies(tr_y).values
    val_y = pd.get_dummies(val_y).values
    model = CNN(emb_input_dim=301, emb_output_dim=256,
            pad_length=7000, num_filters=64 )

    model_weight_name = "Model_textcnn_7k_weight_%s.pkl" % i
    early_stopping =EarlyStopping(monitor='val_loss', patience=10)
    checkpoint = ModelCheckpoint(model_weight_name, save_best_only=True, save_weights_only=True)
    # tensorBoard = keras.callbacks.TensorBoard(log_dir="./TXTCNN/Graph", histogram_freq=1, write_graph=True, write_images=True)

    model.fit(tr_X, tr_y,
              validation_data=(val_X, val_y),
              epochs=100, batch_size=64,
              shuffle=True,
              class_weight=cls_wt,
              callbacks=[early_stopping, checkpoint])
    model.load_weights(model_weight_name)
    pred_val_X = model.predict(val_X, batch_size=64, verbose=1)
    pred_test = model.predict(pad_seq_test, batch_size=64, verbose=1)
    result_val[[val_index]] = pred_val_X
    result_test += pred_test
result_test /=5



pd.DataFrame(result_val).to_csv("textcnn_train_7k_5f_cw.csv")
pd.DataFrame(result_test).to_csv("textcnn_test_7k_5average_cw.csv")

